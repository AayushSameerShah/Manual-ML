{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LVQ. <br>Really is a new thinking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saw how it works and how it is calculated. There is **really**, **really** simple implementation to which you will say \"Wow this simple?\" But I suppose that in the *sklearn* or in the *actual implementation* there would be *slightly more* to it like real neural nets.\n",
    "\n",
    "The way we are going to follow is **without neural net**, because you will see that we don't actully need any kind of that structure. We just want to update the values in each *layer*. <br>\n",
    "‚Äî<br>\n",
    "So, let's go ‚àû"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great stuff to import!\n",
    "import pandas as pd, numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same data that we used for KNN\n",
    "X1 = [3.393533211, 3.110073483, 1.343808831,\n",
    "      3.582294042, 2.280362439, 7.423436942,\n",
    "      5.745051997, 9.172168622, 7.792783481,\n",
    "      7.939820817]\n",
    "\n",
    "X2 = [2.331273381, 1.781539638, 3.368360954,\n",
    "      4.67917911, 2.866990263, 4.696522875,\n",
    "      3.533989803, 2.511101045, 3.424088941,\n",
    "      0.791637231]\n",
    "\n",
    "y = [0] * 5 + [1] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.393533</td>\n",
       "      <td>2.331273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.110073</td>\n",
       "      <td>1.781540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.343809</td>\n",
       "      <td>3.368361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.582294</td>\n",
       "      <td>4.679179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.280362</td>\n",
       "      <td>2.866990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.423437</td>\n",
       "      <td>4.696523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.745052</td>\n",
       "      <td>3.533990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.172169</td>\n",
       "      <td>2.511101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.792783</td>\n",
       "      <td>3.424089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.939821</td>\n",
       "      <td>0.791637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2  y\n",
       "0  3.393533  2.331273  0\n",
       "1  3.110073  1.781540  0\n",
       "2  1.343809  3.368361  0\n",
       "3  3.582294  4.679179  0\n",
       "4  2.280362  2.866990  0\n",
       "5  7.423437  4.696523  1\n",
       "6  5.745052  3.533990  1\n",
       "7  9.172169  2.511101  1\n",
       "8  7.792783  3.424089  1\n",
       "9  7.939821  0.791637  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"x1\":X1, \n",
    "                   \"x2\":X2,\n",
    "                   \"y\":y})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have the data - we have some **basic steps**:\n",
    "1. Set how many **layers**, **initial learning rate**, and **epochs**.\n",
    "2. **Initialize** the *so called* neural net with some random values from training data and also the y.\n",
    "3. For that epoch and that learning rate, **take one by one** row from training dataset.\n",
    "4. For that row, **compare the distances** between all layers in the so called NN.\n",
    "5. Pick the **least distanced** data point. Yes just 1.\n",
    "6. We call it **BMU** (Best Measurable Unit).\n",
    "7. **If** the BMU's class (from NN) is **same as** that row's class, then ***promote*** that BMU's features based on the learning rate currently is.\n",
    "8. **If** the BMU's class is **not same as** that row's class, then ***demote*** that BMU's features based on the learning rate currently is.\n",
    "9. Then **fetch next row** and repeat steps 4-8 again till the entire dataset is traversed one time.\n",
    "10. After 9th step, we will have **a dataset traversed**. It is an **epoch**. Update the learning rate based on the formula given above.\n",
    "11. Run step 4-10 for **n number of epochs** set already.\n",
    "12. After 11th step (traversing for n number of times) we will have our learnt **NN ready**. With the updated attributes.\n",
    "\n",
    "*(Actully I don't like to call the final representation as NN, because NN is an entirely different thing. But for the sake of this algorithm, we are gonna call is as such)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setting layers, LR, epochs\n",
    "n_layers = 4\n",
    "LearningRate = 0.7\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_55a51ea5_179b_11ec_8634_3c6aa7974e64row0_col0,#T_55a51ea5_179b_11ec_8634_3c6aa7974e64row3_col1{\n",
       "            background-color:  #a66efa;\n",
       "        }#T_55a51ea5_179b_11ec_8634_3c6aa7974e64row0_col1,#T_55a51ea5_179b_11ec_8634_3c6aa7974e64row8_col0{\n",
       "            background-color:  #4287f5;\n",
       "        }#T_55a51ea5_179b_11ec_8634_3c6aa7974e64row3_col0,#T_55a51ea5_179b_11ec_8634_3c6aa7974e64row9_col1{\n",
       "            background-color:  #f54295;\n",
       "        }#T_55a51ea5_179b_11ec_8634_3c6aa7974e64row4_col1,#T_55a51ea5_179b_11ec_8634_3c6aa7974e64row9_col0{\n",
       "            background-color:  #42e0f5;\n",
       "        }</style><table id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >x1</th>        <th class=\"col_heading level0 col1\" >x2</th>        <th class=\"col_heading level0 col2\" >y</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row0_col0\" class=\"data row0 col0\" >3.393533</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row0_col1\" class=\"data row0 col1\" >2.331273</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row1_col0\" class=\"data row1 col0\" >3.110073</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row1_col1\" class=\"data row1 col1\" >1.781540</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row2_col0\" class=\"data row2 col0\" >1.343809</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row2_col1\" class=\"data row2 col1\" >3.368361</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row3_col0\" class=\"data row3 col0\" >3.582294</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row3_col1\" class=\"data row3 col1\" >4.679179</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row4_col0\" class=\"data row4 col0\" >2.280362</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row4_col1\" class=\"data row4 col1\" >2.866990</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row5_col0\" class=\"data row5 col0\" >7.423437</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row5_col1\" class=\"data row5 col1\" >4.696523</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row5_col2\" class=\"data row5 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row6_col0\" class=\"data row6 col0\" >5.745052</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row6_col1\" class=\"data row6 col1\" >3.533990</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row6_col2\" class=\"data row6 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row7_col0\" class=\"data row7 col0\" >9.172169</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row7_col1\" class=\"data row7 col1\" >2.511101</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row7_col2\" class=\"data row7 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row8_col0\" class=\"data row8 col0\" >7.792783</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row8_col1\" class=\"data row8 col1\" >3.424089</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row8_col2\" class=\"data row8 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row9_col0\" class=\"data row9 col0\" >7.939821</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row9_col1\" class=\"data row9 col1\" >0.791637</td>\n",
       "                        <td id=\"T_55a51ea5_179b_11ec_8634_3c6aa7974e64row9_col2\" class=\"data row9 col2\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21805974f40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kindly ignore this code\n",
    "def styling_1(df):\n",
    "    purple = \"#a66efa\"\n",
    "    blue = \"#4287f5\"\n",
    "    pink = \"#f54295\"\n",
    "    green = \"#42e0f5\"\n",
    "    \n",
    "    df_styler = pd.DataFrame('', index= df.index, columns= df.columns)\n",
    "    df_styler.iloc[3, 0] = f'background-color: {pink}'\n",
    "    df_styler.iloc[9, 1] = f'background-color: {pink}'\n",
    "    \n",
    "    df_styler.iloc[8, 0] = f'background-color: {blue}'\n",
    "    df_styler.iloc[0, 1] = f'background-color: {blue}'\n",
    "    \n",
    "    df_styler.iloc[9, 0] = f'background-color: {green}'\n",
    "    df_styler.iloc[4, 1] = f'background-color: {green}'\n",
    "    \n",
    "    df_styler.iloc[0, 0] = f'background-color: {purple}'\n",
    "    df_styler.iloc[3, 1] = f'background-color: {purple}'\n",
    "    return df_styler\n",
    "\n",
    "df.style.apply(styling_1, axis= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize the NN \n",
    "# (we will pick the numbers randomly but for now we will\n",
    "#  pick from the book to tallyup the results)\n",
    "NN = pd.DataFrame({\"x1\": [3.582294, 7.792783, 7.939821, 3.393533],\n",
    "                   \"x2\": [0.791637, 2.331273, 2.866990, 4.679179],\n",
    "                   \"y\" : [0       , 0       , 1       , 1       ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_5210aefe_179a_11ec_82be_3c6aa7974e64row0_col0,#T_5210aefe_179a_11ec_82be_3c6aa7974e64row0_col1{\n",
       "            background-color:  #f54295;\n",
       "        }#T_5210aefe_179a_11ec_82be_3c6aa7974e64row1_col0,#T_5210aefe_179a_11ec_82be_3c6aa7974e64row1_col1{\n",
       "            background-color:  #4287f5;\n",
       "        }#T_5210aefe_179a_11ec_82be_3c6aa7974e64row2_col0,#T_5210aefe_179a_11ec_82be_3c6aa7974e64row2_col1{\n",
       "            background-color:  #42e0f5;\n",
       "        }#T_5210aefe_179a_11ec_82be_3c6aa7974e64row3_col0,#T_5210aefe_179a_11ec_82be_3c6aa7974e64row3_col1{\n",
       "            background-color:  #a66efa;\n",
       "        }</style><table id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >x1</th>        <th class=\"col_heading level0 col1\" >x2</th>        <th class=\"col_heading level0 col2\" >y</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row0_col0\" class=\"data row0 col0\" >3.582294</td>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row0_col1\" class=\"data row0 col1\" >0.791637</td>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row1_col0\" class=\"data row1 col0\" >7.792783</td>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row1_col1\" class=\"data row1 col1\" >2.331273</td>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row2_col0\" class=\"data row2 col0\" >7.939821</td>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row2_col1\" class=\"data row2 col1\" >2.866990</td>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row3_col0\" class=\"data row3 col0\" >3.393533</td>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row3_col1\" class=\"data row3 col1\" >4.679179</td>\n",
       "                        <td id=\"T_5210aefe_179a_11ec_82be_3c6aa7974e64row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21803f57cd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kindly ignore this code\n",
    "def styling_2(df):\n",
    "    df_styler = pd.DataFrame('', index= df.index, columns= df.columns)\n",
    "    df_styler.iloc[0, :-1] = 'background-color: #f54295'\n",
    "    df_styler.iloc[1, :-1] = 'background-color: #4287f5'\n",
    "    df_styler.iloc[2, :-1] = 'background-color: #42e0f5'\n",
    "    df_styler.iloc[3, :-1] = 'background-color: #a66efa'\n",
    "    return df_styler\n",
    "\n",
    "NN.style.apply(styling_2, axis= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.55116434, 4.39924979, 4.57774234, 2.34790562])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Take one row at a time and update\n",
    "### taking only first row ‚Üì\n",
    "row = df.iloc[0].values[:-1]\n",
    "\n",
    "# 4. Calculate the distance for all rows in NN\n",
    "def euclidean_distance(A, B):\n",
    "    return ((A - B) ** 2).sum(1) ** 0.5\n",
    "\n",
    "### passing whole NN as `B` ‚Üì\n",
    "distances = euclidean_distance(row, NN.iloc[:, :-1].values)\n",
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚Üë This shows that very **first layer** in the NN with `1.55116` euclidean distance - is the candidate to be our BMU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    3.582294\n",
       "x2    0.791637\n",
       "y     0.000000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Pick the least distanced layer and call it BMU\n",
    "# 6. And call it BMU\n",
    "bmu = NN.iloc[distances.argmin()]\n",
    "bmu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.argmin` will return the index of the least distanced row. Here, we have it on `0th` index so now the updation will happen on that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. or 8. If class same then promote otherwise demote\n",
    "bmu[\"y\"] == df.iloc[0][\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does! So we will promote the BMU with the respective values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ \\text{layer} = \\text{layer} + \\text{LearningRate} \\times (x - \\text{layer}) $\n",
    "###### Here, $\\text{layer} = \\text{bmu}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    3.450161\n",
       "x2    1.869382\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_bmu = bmu.iloc[:-1] + LearningRate * (row - bmu.iloc[:-1])\n",
    "new_bmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting that in NN\n",
    "NN.iloc[0, :-1] = new_bmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row0_col0,#T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row0_col1{\n",
       "            background-color:  #f54295;\n",
       "        }</style><table id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >x1</th>        <th class=\"col_heading level0 col1\" >x2</th>        <th class=\"col_heading level0 col2\" >y</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row0_col0\" class=\"data row0 col0\" >3.450161</td>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row0_col1\" class=\"data row0 col1\" >1.869382</td>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row1_col0\" class=\"data row1 col0\" >7.792783</td>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row1_col1\" class=\"data row1 col1\" >2.331273</td>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row2_col0\" class=\"data row2 col0\" >7.939821</td>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row2_col1\" class=\"data row2 col1\" >2.866990</td>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row3_col0\" class=\"data row3 col0\" >3.393533</td>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row3_col1\" class=\"data row3 col1\" >4.679179</td>\n",
       "                        <td id=\"T_09daeb93_179e_11ec_8a8a_3c6aa7974e64row3_col2\" class=\"data row3 col2\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21806325220>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def styling(df):\n",
    "    df_styler = pd.DataFrame('', index= df.index, columns= df.columns)\n",
    "    df_styler.iloc[0, :-1] = 'background-color: #f54295'\n",
    "    return df_styler\n",
    "\n",
    "NN.style.apply(styling, axis= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BMU (in pink color) is now updated with new values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚Äî<br>\n",
    "Now, as out pseudo code goes - we have to iterate through whole dataset for `n` times and update the values as required. So, let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.values:\n",
    "    distances = euclidean_distance(row[:-1], NN.iloc[:, :-1].values)\n",
    "    bmu_at = distances.argmin()\n",
    "    bmu = NN.iloc[bmu_at]\n",
    "    if bmu[\"y\"] == row[-1]:\n",
    "        new_bmu = bmu.iloc[:-1] + LearningRate * (row[:-1] - bmu.iloc[:-1])\n",
    "    else:\n",
    "        new_bmu = bmu.iloc[:-1] - LearningRate * (row[:-1] - bmu.iloc[:-1])\n",
    "    NN.iloc[bmu_at, :-1] = new_bmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.559884</td>\n",
       "      <td>2.549261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.048388</td>\n",
       "      <td>3.195023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.343461</td>\n",
       "      <td>3.512290</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.700572</td>\n",
       "      <td>6.239052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2  y\n",
       "0  2.559884  2.549261  0\n",
       "1  6.048388  3.195023  0\n",
       "2  7.343461  3.512290  1\n",
       "3  5.700572  6.239052  1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after an epoch (only 1) we have this ‚Üë NN values. Now, of course we can iterate over it more and more... but for now let's go an predict. \n",
    "\n",
    "*(I know the part of \"Updating Learning Rate\" is still not implemented here... but it will be included when we make the class for this LVQ).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction<br>‚Äî"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can say that, we are using KNN here. Yes. For prediction we have to take the new instances and for defined `k` value we have to ask for votes. \n",
    "\n",
    "The main advantage is that, our dataset now has shrunk down from 10 rows to just 4. Imagine a dataset contain 10,000 rows and we shrunk it down to 100 rows only! Much faster algorithm, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our own KNN implementation is being imported\n",
    "from KNN import KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = NN.drop(\"y\", axis=1)\n",
    "y = NN[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.393533</td>\n",
       "      <td>2.331273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.110073</td>\n",
       "      <td>1.781540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.343809</td>\n",
       "      <td>3.368361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.582294</td>\n",
       "      <td>4.679179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.280362</td>\n",
       "      <td>2.866990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.423437</td>\n",
       "      <td>4.696523</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.745052</td>\n",
       "      <td>3.533990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.172169</td>\n",
       "      <td>2.511101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.792783</td>\n",
       "      <td>3.424089</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.939821</td>\n",
       "      <td>0.791637</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2  y  pred\n",
       "0  3.393533  2.331273  0     0\n",
       "1  3.110073  1.781540  0     0\n",
       "2  1.343809  3.368361  0     0\n",
       "3  3.582294  4.679179  0     0\n",
       "4  2.280362  2.866990  0     0\n",
       "5  7.423437  4.696523  1     1\n",
       "6  5.745052  3.533990  1     0\n",
       "7  9.172169  2.511101  1     1\n",
       "8  7.792783  3.424089  1     1\n",
       "9  7.939821  0.791637  1     1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pred\"] = model.predict(df[[\"x1\", \"x2\"]], k=2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.y == df.pred).sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is getting `90%` accuracy. Of course some more epochs are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the compact class<br>‚Äî \n",
    "*Here again, I will try to implement the same in numpy for much faster work*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %load KNN.py\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "class KNN:\n",
    "    \"\"\"\n",
    "    This model is so great. It also can work on 4 different\n",
    "    types of distance metrics.\n",
    "    \n",
    "    First time, I tried to make a model entirely in numpy.\n",
    "    Haven't used a single bit of pandas. It makes numpy stronger\n",
    "    and calculation faster.\n",
    "    \n",
    "    \n",
    "    How To\n",
    "    ------\n",
    "    \n",
    "    >>> model = KNN(X, y)\n",
    "    >>> pred = model.predict(X, k=3, dis_type=\"euclidean\")\n",
    "    \"\"\"\n",
    "    def __init__(self, X: np.ndarray, y: list):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        if X.ndim != 2:\n",
    "            raise NotImplementedError(\\\n",
    "            \"\"\"\n",
    "            The dimention of the features \n",
    "            must be 2D.\n",
    "            \"\"\")\n",
    "        if (len(X) != len(y)) or (y.ndim != 1):\n",
    "            raise NotImplementedError(\\\n",
    "            \"\"\"\n",
    "            The length of features \n",
    "            and target mismatched.\n",
    "            \"\"\")\n",
    "        self.stored_X = X\n",
    "        self.stored_y = y\n",
    "        \n",
    "    \n",
    "    def predict(self, X: np.ndarray, k: int, dis_type=\"euclidean\", p=None):\n",
    "        X = np.array(X)\n",
    "        self.dis_type = dis_type\n",
    "        if (self.dis_type == \"minkowaski\") and (p == None):\n",
    "            raise NotImplementedError(\"Please provide `p` value.\")\n",
    "        self.p = p    \n",
    "        if X.ndim != 2:\n",
    "            raise NotImplementedError(\\\n",
    "            \"\"\"\n",
    "            The dimention of the features \n",
    "            must be 2D.\n",
    "            \"\"\")\n",
    "        pred_classes = []\n",
    "        for each_row in X:\n",
    "            distance = self.get_distance(row=each_row)\n",
    "            sorted_k_indexes = np.argsort(distance)[:k]\n",
    "            pred_class = statistics.mode(self.stored_y[sorted_k_indexes])\n",
    "            pred_classes.append(pred_class)\n",
    "        return pred_classes\n",
    "    \n",
    "    def get_distance(self, row):\n",
    "        if self.dis_type == \"euclidean\":\n",
    "            return ((row - self.stored_X) ** 2).sum(1) ** 0.5\n",
    "        elif self.dis_type == \"manhattan\":\n",
    "            return abs((row - self.stored_X)).sum(1)\n",
    "        elif self.dis_type == \"hamming\":\n",
    "            return abs(row - self.stored_X).sum(1) / len(row)\n",
    "        elif self.dis_type == \"minkowaski\":\n",
    "            return (abs(row - self.stored_X) ** self.p).sum(1) ** (1 / self.p)\n",
    "        else:\n",
    "            raise NotImplementedError(\\\n",
    "            f\"\"\"\n",
    "            The distance type chosen is `{self.dis_type}`.\n",
    "            Please choose from: \n",
    "            ‚Ä¢ euclidean\n",
    "            ‚Ä¢ manhattan\n",
    "            ‚Ä¢ hamming\n",
    "            ‚Ä¢ minkowaski\n",
    "            \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing LVQ_KNN.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile LVQ_KNN.py\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from KNN import KNN\n",
    "\n",
    "\n",
    "class LVQ_KNN:\n",
    "    \"\"\"\n",
    "    This class is implemented to build LVQ model.\n",
    "    It gives a nice range of hyperparameters to tune\n",
    "    and works much faster than the traditional KNN.\n",
    "    \n",
    "    For the prediction part, it uses KNN though, but\n",
    "    with the less number of layers, it works amazingly fast.\n",
    "    \n",
    "    How To\n",
    "    ------\n",
    "        # Prepare X and y\n",
    "    >>> X = iris.drop(\"species\", axis=1)\n",
    "    ... y = iris[\"species\"]\n",
    "    \n",
    "        # Train\n",
    "    >>> model = LVQ_KNN(X, y, n_layers=10, \n",
    "                        learning_rate=0.3, epochs=200,\n",
    "                        learning_mode=\"static / dynamic\")\n",
    "    >>> model.predict(X)                              \n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, n_layers, learning_rate=0.3, epochs=2,\n",
    "                 learning_mode=\"dynamic\"):\n",
    "        self.X = np.array(X); self.y = np.array(y)\n",
    "        self.n_layers = n_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.learning_mode = learning_mode\n",
    "        \n",
    "        if X.ndim != 2:\n",
    "            raise NotImplementedError(\\\n",
    "            \"\"\"\n",
    "            The dimention of the features \n",
    "            must be 2D.\n",
    "            \"\"\")\n",
    "        if (len(X) != len(y)) or (y.ndim != 1):\n",
    "            raise NotImplementedError(\\\n",
    "            \"\"\"\n",
    "            The length of features \n",
    "            and target mismatched.\n",
    "            \"\"\")\n",
    "        if n_layers > len(self.X):\n",
    "            raise NotImplementedError(\\\n",
    "            \"\"\"\n",
    "            `n_layers` must be less than\n",
    "            total rows in dataset.\n",
    "            \"\"\")\n",
    "            \n",
    "        self.NN = self.randomize_init()\n",
    "        for epoch in range(self.epochs):\n",
    "            # LearningRate = LearningRate √ó (1 ‚àí ùëõùë°‚ÑéEpoch / TotalEpochs)\n",
    "            if self.learning_mode == \"dynamic\":\n",
    "                self.learning_rate = self.learning_rate * (1 - epoch / self.epochs)\n",
    "            self.compress_data()\n",
    "        \n",
    "        \n",
    "    def randomize_init(self):\n",
    "        shuffled_X = None\n",
    "        for column in range(self.X.shape[1]):\n",
    "            mask = np.random.permutation(self.X.shape[0])[:self.n_layers]\n",
    "            if shuffled_X is None:\n",
    "                shuffled_X = self.X[mask, column]\n",
    "            else:\n",
    "                shuffled_X = np.c_[shuffled_X, self.X[mask, column]]\n",
    "        self.stratified_y_column = self.stratified_sampling()[: self.n_layers]\n",
    "        return shuffled_X\n",
    "     \n",
    "        \n",
    "    def compress_data(self):\n",
    "        for row in self.X:\n",
    "            distances = self.euclidean_distance(row, self.NN)\n",
    "            bmu_at = distances.argmin()\n",
    "            bmu = self.NN[bmu_at]\n",
    "            if self.y[bmu_at] == self.stratified_y_column[bmu_at]:\n",
    "                new_bmu = bmu + self.learning_rate * (row - bmu)\n",
    "            else:\n",
    "                new_bmu = bmu - self.learning_rate * (row - bmu)\n",
    "            self.NN[bmu_at] = new_bmu\n",
    "    \n",
    "    \n",
    "    def predict(self, X, k):\n",
    "        model = KNN(self.NN, self.stratified_y_column)\n",
    "        return model.predict(X, k=k)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean_distance(A, B):\n",
    "        return ((A - B) ** 2).sum(1) ** 0.5\n",
    "    \n",
    "    \n",
    "    def stratified_sampling(self):\n",
    "        total = len(self.y)\n",
    "        new_y = []\n",
    "        for class_, count in zip(*np.unique(self.y, return_counts=True)):\n",
    "            new_count = math.ceil((count * self.n_layers) / total)\n",
    "            new_y.extend(np.full(new_count, class_))\n",
    "        return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"x1\", \"x2\"]]\n",
    "y = df[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LVQ_KNN(X, y, 4, 0.001, epochs=200, learning_mode=\"static\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomize nature sometimes gives in appropriate results... but for now it seems to be working.\n",
    "\n",
    "Let's try it on the new dataset, our old `iris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop(\"species\", axis=1)\n",
    "y = iris[\"species\"]\n",
    "\n",
    "model = LVQ_KNN(X, y, n_layers=20,\n",
    "               learning_rate=0.01, epochs=500, \n",
    "               learning_mode=\"static\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X, k=12)\n",
    "(pred == y).sum() / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a good accuracy at all... but still it is there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it!\n",
    "Next up, we will learn a new algorithm!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
