{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "*A new approach to classification by using the old approach*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM** is one of the oldest and high performing, go-to algorithms in the ML market. It requires a little tuning and is as easy to understand as we did with the linear regression. \n",
    "\n",
    "> ***SVM is a strict - binaray classification model*** but it can be used for multiclass classification by stacking. \n",
    "\n",
    "Let me be clear with some terminology. We will be get confused between **Support vector machine** and **Support vector classifier**.\n",
    "\n",
    " - Support Vector Machine is a technique which includes the a set of *kernels* to transform the data from low dimensions to relatively high dimentions.\n",
    "     - Now, *kernel* is a simple equation which actually does the transformation of the data from low dimention to high. There are kernels like - Linear, Polynomial, Radial etc.\n",
    "     - SVM does this because the data we have in lower dimention, in which we can't simply draw the classifier. So we need to see the data in higher dimention, which well increases the number of parameters.\n",
    "     \n",
    "- Support Vector Classifier is the line which is drawn in between the two classes for seperation. It is learnt from the data. And it includes the Maximal Margin Classifier (the 2 dashed lines around it).\n",
    "\n",
    "Things will get a little more clear when we see things in action. But for now, I hope the terms are very clear. We call this whole thing as \"SVM\" because the SVM is the one which plays a key role in it.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other terms<br>—\n",
    "1. **margin**: The distance between the line and the closest data points is known as margin.\n",
    "\n",
    "2. **maximal margin classifier**: The best or optimal line that best seperates two classes and has the largest margin.\n",
    "\n",
    "3. **support vectors**: The points which are relavent in defining the line and are the first closest to the line are the support vectors.\n",
    "\n",
    "4. **soft margin classifier**: It is the situation where we allow some misclassification to define the line. Which results in high bias and low variance. Defined by `C`.\n",
    "\n",
    "5. **support vector machines / kernels**: As said, they SVM is the collection of kernels. It is the learning of the hyperplane in linear SMV done by transforming the problem using some linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Line\n",
    "\n",
    "# $$ \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Equation\n",
    "\n",
    "# $$ f(x) = \\beta_0 + \\sum(\\beta_i \\times (x \\times \\text{vec}_i)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO BE UPDATED ↑ (both of them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LINEAR KERNEL\n",
    "\n",
    "# $$ K(x, \\text{vec}) = \\sum(x \\cdot \\text{vec})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POLYNOMIAL KERNEL\n",
    "\n",
    "# $$ K(x, \\text{vec}) =1 + \\sum(x \\cdot \\text{vec})^d$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RADIAL KERNEL\n",
    "\n",
    "# $$ K(x, \\text{vec}) = e^{-\\text{gamma} \\times \\sum(x - \\text{vec}^2)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM model needs to be solved using an optimization procedure. <br>\n",
    "We can:\n",
    "1. SMO (Sequetial Minimal Optimization) - The most popular\n",
    "2. Sub - GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of them can be used to find the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we use Sub - GD then,\n",
    "To update the weights we need to follow the following formulaes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GET OUTPUT\n",
    "# $$ \\text{output} = y \\times (\\beta_1 x_1) + (\\beta_2 x_2) + \\beta_0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IF $ \\text{output} $ GREATER THAN 1\n",
    "\n",
    "# $$ \\beta_\\text{i or 0} = \\left(1 - \\frac{1} {t}\\right) \\times \\beta_\\text{i or 0} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IF $ \\text{output} $ LESS THAN 1 (coefs)\n",
    "\n",
    "### $$ \\beta_i = \\left(1 - \\frac{1} {t}\\right) \\times \\beta_i +  \\frac {1} {\\text{LearningRate} \\times t} \\times (y \\times x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IF $ \\text{output} $ LESS THAN 1 (intercept)\n",
    "\n",
    "### $$ \\beta_0 = \\left(1 - \\frac{1} {t}\\right) \\times \\beta_0 +  \\frac {1} {\\text{LearningRate} \\times t} \\times y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next up\n",
    "We will see how can we take some dataset and solve the classification problem to get the clear understanding of the model's internals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
